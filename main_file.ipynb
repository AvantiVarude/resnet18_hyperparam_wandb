{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Train a ResNet18 model for classification on even classes of CIFAR-10"
      ],
      "metadata": {
        "id": "VWs9pj6MQpzc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import required libraries"
      ],
      "metadata": {
        "id": "ZRvno9-UQmZB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Import all required libraries\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch import nn\n",
        "from tqdm import tqdm\n",
        "from time import time\n",
        "from torch import optim\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms, models\n",
        "from tqdm import tqdm\n",
        "import timeit\n",
        "import math\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "BdvEQdEkpHgd"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install wandb library"
      ],
      "metadata": {
        "id": "gvaw-o-BciqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EqTO_UnYpHj_",
        "outputId": "b92806e8-9c97-4a7c-85c1-da5e57954d52"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wandb\n",
            "  Downloading wandb-0.15.10-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb)\n",
            "  Downloading GitPython-3.1.36-py3-none-any.whl (189 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m189.5/189.5 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
            "  Downloading sentry_sdk-1.30.0-py2.py3-none-any.whl (218 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m218.8/218.8 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
            "Collecting pathtools (from wandb)\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting setproctitle (from wandb)\n",
            "  Downloading setproctitle-1.3.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2023.7.22)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: pathtools\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8791 sha256=8616f4b46a8fcaa5bd5df799639bf5abe70f689d7418c91099dfeb8b18b37284\n",
            "  Stored in directory: /root/.cache/pip/wheels/e7/f3/22/152153d6eb222ee7a56ff8617d80ee5207207a8c00a7aab794\n",
            "Successfully built pathtools\n",
            "Installing collected packages: pathtools, smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, GitPython, wandb\n",
            "Successfully installed GitPython-3.1.36 docker-pycreds-0.4.0 gitdb-4.0.10 pathtools-0.1.2 sentry-sdk-1.30.0 setproctitle-1.3.2 smmap-5.0.0 wandb-0.15.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import and login"
      ],
      "metadata": {
        "id": "l-NKahYQcl8M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "id": "UJAwdn2npHlU",
        "outputId": "3560602b-5b4d-471d-d33d-4b0fb2f5d17f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 路路路路路路路路路路\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mWXMpQUWRCM6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apply transforms"
      ],
      "metadata": {
        "id": "dz19d03Ygzy3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the transforms for data preprocessing\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "# Load the Fashion MNIST dataset\n",
        "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "inhyOWeanoDP",
        "outputId": "9ee23886-bc72-480e-e555-c3c02daedc71"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 170498071/170498071 [00:02<00:00, 61957776.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract only even classes from the dataset"
      ],
      "metadata": {
        "id": "286sFtCJg1ms"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Changing the labels of even number to 10 for further operations\n",
        "train_dataset.targets = torch.tensor(train_dataset.targets)\n",
        "train_dataset.targets[train_dataset.targets ==1] = 10\n",
        "train_dataset.targets[train_dataset.targets ==3] = 10\n",
        "train_dataset.targets[train_dataset.targets ==5] = 10\n",
        "train_dataset.targets[train_dataset.targets ==7] = 10\n",
        "train_dataset.targets[train_dataset.targets ==9] = 10\n",
        "\n",
        "#changing the labels of odd number starting from 0 to 4 to have good indexing and labeling for model\n",
        "train_dataset.targets[train_dataset.targets ==0] = 0\n",
        "train_dataset.targets[train_dataset.targets ==2] = 1\n",
        "train_dataset.targets[train_dataset.targets ==4] = 2\n",
        "train_dataset.targets[train_dataset.targets ==6] = 3\n",
        "train_dataset.targets[train_dataset.targets ==8] = 4\n",
        "print(train_dataset.targets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5woHIHoLREws",
        "outputId": "a616e0e7-ae43-486c-c72e-2352556847dc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 3, 10, 10,  ..., 10, 10, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Changing the labels of even number to 10 for further operations\n",
        "test_dataset.targets = torch.tensor(test_dataset.targets)\n",
        "test_dataset.targets[test_dataset.targets ==1] = 10\n",
        "test_dataset.targets[test_dataset.targets ==3] = 10\n",
        "test_dataset.targets[test_dataset.targets ==5] = 10\n",
        "test_dataset.targets[test_dataset.targets ==7] = 10\n",
        "test_dataset.targets[test_dataset.targets ==9] = 10\n",
        "\n",
        "#changing the labels of odd number starting from 0 to 4 to have good indexing and labeling for model\n",
        "test_dataset.targets[test_dataset.targets ==0] = 0\n",
        "test_dataset.targets[test_dataset.targets ==2] = 1\n",
        "test_dataset.targets[test_dataset.targets ==4] = 2\n",
        "test_dataset.targets[test_dataset.targets ==6] = 3\n",
        "test_dataset.targets[test_dataset.targets ==8] = 4\n",
        "\n",
        "print(test_dataset.targets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4G6ivB43RMq6",
        "outputId": "9a0321c6-3509-41f6-95f5-86e39ae69994"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([10,  4,  4,  ..., 10, 10, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create the mask to get required data from tha main dataset\n",
        "#If the label is other than 10 (Remember the even number labels are changed to 10) then make that true for training and testing data\n",
        "train_mask = (torch.tensor(train_dataset.targets) != 10)\n",
        "test_mask = (torch.tensor(test_dataset.targets) != 10)\n",
        "\n",
        "#Get the indices of the labels which are marked true\n",
        "train_indices = train_mask.nonzero().reshape(-1)\n",
        "test_indices =test_mask.nonzero().reshape(-1)\n",
        "\n",
        "#Select the subset from the mask that is created above\n",
        "trainset_2 = torch.utils.data.Subset(train_dataset, train_indices)\n",
        "testset_2 = torch.utils.data.Subset(test_dataset, test_indices)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cs9ISPgrRR3Q",
        "outputId": "4739ce5b-4361-4161-de3f-afca2eed7bda"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-930f6bba34b0>:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  train_mask = (torch.tensor(train_dataset.targets) != 10)\n",
            "<ipython-input-7-930f6bba34b0>:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  test_mask = (torch.tensor(test_dataset.targets) != 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7aRQBeEmRR4p"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6AlFg9VGRR8P"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get resnet18 pretrained model"
      ],
      "metadata": {
        "id": "zGvym6HUhELd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the ResNet18 model pre-trained on ImageNet\n",
        "model = models.resnet18(pretrained=True)\n",
        "\n",
        "# Modify the last fully connected layer to output 10 classes\n",
        "num_classes = 5\n",
        "model.fc = nn.Linear(512, num_classes)\n",
        "#get  model to device\n",
        "model=model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvoMaJt5noEm",
        "outputId": "32b4ed47-9861-49c8-e1ce-afdcbbee5cb2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|| 44.7M/44.7M [00:00<00:00, 106MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "loss function"
      ],
      "metadata": {
        "id": "HbE4qEtLhG20"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make the loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "zgQYwDnh5inq"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "toplot the prediction of ini=dividual image on the weights and bias"
      ],
      "metadata": {
        "id": "sQ2LMT2LhIJz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def log_image_table(images, predicted, labels, probs):\n",
        "    \"Log a wandb.Table with (img, pred, target, scores)\"\n",
        "    #  Create a wandb Table to log images, labels and predictions to\n",
        "    table = wandb.Table(columns=[\"image\", \"pred\", \"target\"]+[f\"score_{i}\" for i in range(5)])\n",
        "    for img, pred, targ, prob in zip(images.to(\"cpu\"), predicted.to(\"cpu\"), labels.to(\"cpu\"), probs.to(\"cpu\")):\n",
        "        table.add_data(wandb.Image(img[0].numpy()*255), pred, targ, *prob.numpy())\n",
        "    wandb.log({\"predictions_table\":table}, commit=False)"
      ],
      "metadata": {
        "id": "ggQ7xH735vPA"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test function"
      ],
      "metadata": {
        "id": "7JYoS-8RhOM-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_function(model, log_images=False, batch_idx=0):\n",
        "    \"Compute performance of the model on the validation dataset and log a wandb.Table\"\n",
        "    model.eval()\n",
        "    val_loss = 0.\n",
        "    with torch.inference_mode():\n",
        "        correct = 0\n",
        "        for i, (images, labels) in enumerate(test_loader):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            # Forward pass \n",
        "            outputs = model(images)\n",
        "            val_loss += criterion(outputs, labels)*labels.size(0)\n",
        "\n",
        "            # Compute accuracy and accumulate\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            # Log one batch of images to the dashboard, always same batch_idx.\n",
        "            if i==batch_idx and log_images:\n",
        "                log_image_table(images, predicted, labels, outputs.softmax(dim=1))\n",
        "    return val_loss / len(test_loader.dataset), correct / len(test_loader.dataset)"
      ],
      "metadata": {
        "id": "SmgQrtZhC5RT"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model"
      ],
      "metadata": {
        "id": "9iDvTmq9hP5n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main_fun(model, optimizer):\n",
        "  # Training\n",
        "  example_ct = 0\n",
        "  step_ct = 0\n",
        "  total_epochs=30\n",
        "  for epoch in range(total_epochs):\n",
        "      model.train()\n",
        "      train_acc=0\n",
        "      for step, (images, labels) in enumerate(train_loader):\n",
        "          images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "          outputs = model(images)\n",
        "          train_loss = criterion(outputs, labels)\n",
        "          optimizer.zero_grad()\n",
        "          train_loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "          # Compute accuracy and accumulate\n",
        "          total=labels.size(0)\n",
        "          _, tr_pred = torch.max(outputs.data, 1)\n",
        "          tr_correct = (tr_pred == labels).sum().item()\n",
        "          train_acc+=tr_correct\n",
        "          example_ct += len(images)\n",
        "          metrics = {\"train/train_loss\": train_loss,\"train/train_accuracy\": tr_correct/total}\n",
        "\n",
        "          if step + 1 < n_steps_per_epoch:\n",
        "              # Log train metrics to wandb\n",
        "              wandb.log(metrics)\n",
        "\n",
        "          step_ct += 1\n",
        "\n",
        "      val_loss, accuracy = test_function(model, log_images=(epoch==(total_epochs-1)))\n",
        "\n",
        "      # Log train and validation metrics to wandb\n",
        "      val_metrics = {\"val/val_loss\": val_loss,\n",
        "                      \"val/val_accuracy\": accuracy}\n",
        "      wandb.log({**metrics, **val_metrics})\n",
        "\n",
        "      print(f\"Train accuracy: {train_acc/len(train_loader.dataset)}, Train Loss: {train_loss:.3f}, val Loss: {val_loss:3f}, val accuracy: {accuracy:.2f}\")\n",
        "\n",
        "  # If you had a test set, this is how you could log it as a Summary metric\n",
        "  wandb.summary['test_accuracy'] = 0.8\n",
        "\n",
        "  # Close your wandb run\n",
        "  wandb.finish()"
      ],
      "metadata": {
        "id": "JbW7ZJlHDJHE"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Driver code"
      ],
      "metadata": {
        "id": "WShMJGbyhSAs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Hyperparameter Set1"
      ],
      "metadata": {
        "id": "ig7Z7ry3cwCh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create data loaders for training and testing\n",
        "batch_size = 128\n",
        "train_loader = torch.utils.data.DataLoader(trainset_2, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(testset_2, batch_size=batch_size, shuffle=False)\n",
        "n_steps_per_epoch = math.ceil(len(train_loader.dataset) /batch_size)"
      ],
      "metadata": {
        "id": "WTS7q8zxResS"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialise a wandb run\n",
        "wandb.init(\n",
        "    project=\"resnet18_wandb_project\",name=\"Hyper_param1\",\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "0BorCIBKpHt5",
        "outputId": "12ad245f-0c84-429e-abee-911fd8efb728"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mavantivarude2000\u001b[0m (\u001b[33mavanti\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.10"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230913_091548-apk2wq6n</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/avanti/resnet18_wandb_project/runs/apk2wq6n' target=\"_blank\">Hyper_param1</a></strong> to <a href='https://wandb.ai/avanti/resnet18_wandb_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/avanti/resnet18_wandb_project' target=\"_blank\">https://wandb.ai/avanti/resnet18_wandb_project</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/avanti/resnet18_wandb_project/runs/apk2wq6n' target=\"_blank\">https://wandb.ai/avanti/resnet18_wandb_project/runs/apk2wq6n</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/avanti/resnet18_wandb_project/runs/apk2wq6n?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7dfd5cf0aaa0>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "main_fun(model, optimizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 837
        },
        "id": "R21S3y3iC5Yj",
        "outputId": "6ce205c1-5d00-4436-f7f4-2c63d3449b4f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train accuracy: 0.78524, Train Loss: 0.648, val Loss: 0.581873, val accuracy: 0.80\n",
            "Train accuracy: 0.88156, Train Loss: 0.258, val Loss: 0.380121, val accuracy: 0.87\n",
            "Train accuracy: 0.91628, Train Loss: 0.086, val Loss: 0.392378, val accuracy: 0.87\n",
            "Train accuracy: 0.9388, Train Loss: 0.279, val Loss: 0.405331, val accuracy: 0.87\n",
            "Train accuracy: 0.94992, Train Loss: 0.183, val Loss: 0.399076, val accuracy: 0.87\n",
            "Train accuracy: 0.96284, Train Loss: 0.110, val Loss: 0.451942, val accuracy: 0.87\n",
            "Train accuracy: 0.9668, Train Loss: 0.251, val Loss: 0.418286, val accuracy: 0.88\n",
            "Train accuracy: 0.97392, Train Loss: 0.019, val Loss: 0.442639, val accuracy: 0.87\n",
            "Train accuracy: 0.97668, Train Loss: 0.393, val Loss: 0.462765, val accuracy: 0.88\n",
            "Train accuracy: 0.9752, Train Loss: 0.067, val Loss: 0.489602, val accuracy: 0.88\n",
            "Train accuracy: 0.98284, Train Loss: 0.083, val Loss: 0.542273, val accuracy: 0.88\n",
            "Train accuracy: 0.9828, Train Loss: 0.103, val Loss: 0.470788, val accuracy: 0.88\n",
            "Train accuracy: 0.98656, Train Loss: 0.079, val Loss: 0.467499, val accuracy: 0.89\n",
            "Train accuracy: 0.98268, Train Loss: 0.003, val Loss: 0.513921, val accuracy: 0.88\n",
            "Train accuracy: 0.987, Train Loss: 0.005, val Loss: 0.474027, val accuracy: 0.89\n",
            "Train accuracy: 0.9884, Train Loss: 0.027, val Loss: 0.504864, val accuracy: 0.88\n",
            "Train accuracy: 0.98736, Train Loss: 0.080, val Loss: 0.497874, val accuracy: 0.89\n",
            "Train accuracy: 0.98932, Train Loss: 0.090, val Loss: 0.500215, val accuracy: 0.89\n",
            "Train accuracy: 0.99144, Train Loss: 0.061, val Loss: 0.528421, val accuracy: 0.88\n",
            "Train accuracy: 0.98612, Train Loss: 0.005, val Loss: 0.472442, val accuracy: 0.89\n",
            "Train accuracy: 0.9916, Train Loss: 0.006, val Loss: 0.484087, val accuracy: 0.89\n",
            "Train accuracy: 0.99188, Train Loss: 0.026, val Loss: 0.554505, val accuracy: 0.89\n",
            "Train accuracy: 0.99, Train Loss: 0.002, val Loss: 0.485483, val accuracy: 0.88\n",
            "Train accuracy: 0.99316, Train Loss: 0.002, val Loss: 0.517340, val accuracy: 0.89\n",
            "Train accuracy: 0.99152, Train Loss: 0.032, val Loss: 0.491477, val accuracy: 0.89\n",
            "Train accuracy: 0.98976, Train Loss: 0.003, val Loss: 0.495283, val accuracy: 0.89\n",
            "Train accuracy: 0.99384, Train Loss: 0.005, val Loss: 0.603417, val accuracy: 0.88\n",
            "Train accuracy: 0.99096, Train Loss: 0.412, val Loss: 0.493033, val accuracy: 0.89\n",
            "Train accuracy: 0.98988, Train Loss: 0.000, val Loss: 0.510557, val accuracy: 0.89\n",
            "Train accuracy: 0.9936, Train Loss: 0.160, val Loss: 0.598735, val accuracy: 0.88\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/train_accuracy</td><td></td></tr><tr><td>train/train_loss</td><td></td></tr><tr><td>val/val_accuracy</td><td></td></tr><tr><td>val/val_loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_accuracy</td><td>0.8</td></tr><tr><td>train/train_accuracy</td><td>0.95</td></tr><tr><td>train/train_loss</td><td>0.16002</td></tr><tr><td>val/val_accuracy</td><td>0.876</td></tr><tr><td>val/val_loss</td><td>0.59874</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">Hyper_param1</strong> at: <a href='https://wandb.ai/avanti/resnet18_wandb_project/runs/apk2wq6n' target=\"_blank\">https://wandb.ai/avanti/resnet18_wandb_project/runs/apk2wq6n</a><br/>Synced 5 W&B file(s), 1 media file(s), 129 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230913_091548-apk2wq6n/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Hyperparameter set 2:"
      ],
      "metadata": {
        "id": "Syp8GHmQc0s1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create data loaders for training and testing\n",
        "batch_size = 64\n",
        "train_loader = torch.utils.data.DataLoader(trainset_2, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(testset_2, batch_size=batch_size, shuffle=False)\n",
        "n_steps_per_epoch = math.ceil(len(train_loader.dataset) /batch_size)\n",
        "\n",
        "wandb.init(\n",
        "    project=\"resnet18_wandb_project\",name=\"Hyper_param2\",\n",
        ")\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "main_fun(model, optimizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kVFo44xZC5cM",
        "outputId": "ac44d88e-47e4-4a9f-bc19-6f773c41a2e9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing last run (ID:he7jts70) before initializing another..."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/train_accuracy</td><td></td></tr><tr><td>train/train_loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train/train_accuracy</td><td>0.35938</td></tr><tr><td>train/train_loss</td><td>1.61735</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">Hyper_param2</strong> at: <a href='https://wandb.ai/avanti/DLOps_Lab_Assignment8/runs/he7jts70' target=\"_blank\">https://wandb.ai/avanti/DLOps_Lab_Assignment8/runs/he7jts70</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230913_092241-he7jts70/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Successfully finished last run (ID:he7jts70). Initializing new run:<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.10"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230913_092304-390mskwy</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/avanti/resnet18_wandb_project/runs/390mskwy' target=\"_blank\">Hyper_param2</a></strong> to <a href='https://wandb.ai/avanti/resnet18_wandb_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/avanti/resnet18_wandb_project' target=\"_blank\">https://wandb.ai/avanti/resnet18_wandb_project</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/avanti/resnet18_wandb_project/runs/390mskwy' target=\"_blank\">https://wandb.ai/avanti/resnet18_wandb_project/runs/390mskwy</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train accuracy: 0.48208, Train Loss: 1.294, val Loss: 1.259439, val accuracy: 0.51\n",
            "Train accuracy: 0.57688, Train Loss: 1.090, val Loss: 0.925271, val accuracy: 0.62\n",
            "Train accuracy: 0.656, Train Loss: 0.909, val Loss: 0.888508, val accuracy: 0.68\n",
            "Train accuracy: 0.71484, Train Loss: 0.473, val Loss: 0.699629, val accuracy: 0.74\n",
            "Train accuracy: 0.75652, Train Loss: 0.720, val Loss: 0.620912, val accuracy: 0.77\n",
            "Train accuracy: 0.78576, Train Loss: 0.475, val Loss: 0.644418, val accuracy: 0.76\n",
            "Train accuracy: 0.80556, Train Loss: 0.496, val Loss: 0.649045, val accuracy: 0.75\n",
            "Train accuracy: 0.82384, Train Loss: 0.421, val Loss: 0.661013, val accuracy: 0.76\n",
            "Train accuracy: 0.84528, Train Loss: 0.350, val Loss: 0.529666, val accuracy: 0.81\n",
            "Train accuracy: 0.86664, Train Loss: 0.369, val Loss: 0.554757, val accuracy: 0.81\n",
            "Train accuracy: 0.87992, Train Loss: 0.356, val Loss: 0.508617, val accuracy: 0.82\n",
            "Train accuracy: 0.8984, Train Loss: 0.262, val Loss: 0.552544, val accuracy: 0.81\n",
            "Train accuracy: 0.9096, Train Loss: 0.560, val Loss: 0.573653, val accuracy: 0.81\n",
            "Train accuracy: 0.9158, Train Loss: 0.380, val Loss: 0.650324, val accuracy: 0.81\n",
            "Train accuracy: 0.92532, Train Loss: 0.153, val Loss: 0.594725, val accuracy: 0.82\n",
            "Train accuracy: 0.93972, Train Loss: 0.183, val Loss: 0.644675, val accuracy: 0.82\n",
            "Train accuracy: 0.94616, Train Loss: 0.069, val Loss: 0.674184, val accuracy: 0.81\n",
            "Train accuracy: 0.95168, Train Loss: 0.167, val Loss: 0.705844, val accuracy: 0.81\n",
            "Train accuracy: 0.95584, Train Loss: 0.110, val Loss: 0.707536, val accuracy: 0.82\n",
            "Train accuracy: 0.96064, Train Loss: 0.103, val Loss: 0.740899, val accuracy: 0.82\n",
            "Train accuracy: 0.9658, Train Loss: 0.034, val Loss: 0.780899, val accuracy: 0.81\n",
            "Train accuracy: 0.96408, Train Loss: 0.084, val Loss: 0.759903, val accuracy: 0.82\n",
            "Train accuracy: 0.96952, Train Loss: 0.089, val Loss: 0.748765, val accuracy: 0.82\n",
            "Train accuracy: 0.9748, Train Loss: 0.011, val Loss: 0.781141, val accuracy: 0.83\n",
            "Train accuracy: 0.97128, Train Loss: 0.088, val Loss: 0.760365, val accuracy: 0.82\n",
            "Train accuracy: 0.97908, Train Loss: 0.079, val Loss: 0.855617, val accuracy: 0.82\n",
            "Train accuracy: 0.97724, Train Loss: 0.052, val Loss: 0.798464, val accuracy: 0.82\n",
            "Train accuracy: 0.97656, Train Loss: 0.086, val Loss: 0.888204, val accuracy: 0.82\n",
            "Train accuracy: 0.9784, Train Loss: 0.144, val Loss: 0.929165, val accuracy: 0.80\n",
            "Train accuracy: 0.97752, Train Loss: 0.132, val Loss: 0.879731, val accuracy: 0.81\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/train_accuracy</td><td></td></tr><tr><td>train/train_loss</td><td></td></tr><tr><td>val/val_accuracy</td><td></td></tr><tr><td>val/val_loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_accuracy</td><td>0.8</td></tr><tr><td>train/train_accuracy</td><td>0.9</td></tr><tr><td>train/train_loss</td><td>0.13226</td></tr><tr><td>val/val_accuracy</td><td>0.8084</td></tr><tr><td>val/val_loss</td><td>0.87973</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">Hyper_param2</strong> at: <a href='https://wandb.ai/avanti/resnet18_wandb_project/runs/390mskwy' target=\"_blank\">https://wandb.ai/avanti/resnet18_wandb_project/runs/390mskwy</a><br/>Synced 5 W&B file(s), 1 media file(s), 65 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230913_092304-390mskwy/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyperparameter Set 3:"
      ],
      "metadata": {
        "id": "A6tqFOFcc4I_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create data loaders for training and testing\n",
        "batch_size = 64\n",
        "train_loader = torch.utils.data.DataLoader(trainset_2, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(testset_2, batch_size=batch_size, shuffle=False)\n",
        "n_steps_per_epoch = math.ceil(len(train_loader.dataset) /batch_size)\n",
        "\n",
        "wandb.init(\n",
        "    project=\"resnet18_wandb_project\",name=\"Hyper_param3\",\n",
        ")\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001,momentum=0.9)\n",
        "main_fun(model, optimizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 925
        },
        "id": "44b0GN7aC5et",
        "outputId": "26923583-c953-405e-ec8b-e499fa3bbea2"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.10"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230913_093106-qjpc3g8u</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/avanti/resnet18_wandb_project/runs/qjpc3g8u' target=\"_blank\">Hyper_param3</a></strong> to <a href='https://wandb.ai/avanti/resnet18_wandb_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/avanti/resnet18_wandb_project' target=\"_blank\">https://wandb.ai/avanti/resnet18_wandb_project</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/avanti/resnet18_wandb_project/runs/qjpc3g8u' target=\"_blank\">https://wandb.ai/avanti/resnet18_wandb_project/runs/qjpc3g8u</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train accuracy: 0.98436, Train Loss: 0.021, val Loss: 0.843864, val accuracy: 0.82\n",
            "Train accuracy: 0.98672, Train Loss: 0.003, val Loss: 0.829377, val accuracy: 0.82\n",
            "Train accuracy: 0.98804, Train Loss: 0.048, val Loss: 0.837503, val accuracy: 0.82\n",
            "Train accuracy: 0.9892, Train Loss: 0.048, val Loss: 0.820192, val accuracy: 0.82\n",
            "Train accuracy: 0.9908, Train Loss: 0.016, val Loss: 0.821591, val accuracy: 0.82\n",
            "Train accuracy: 0.99032, Train Loss: 0.015, val Loss: 0.822770, val accuracy: 0.83\n",
            "Train accuracy: 0.99128, Train Loss: 0.006, val Loss: 0.835963, val accuracy: 0.83\n",
            "Train accuracy: 0.99208, Train Loss: 0.024, val Loss: 0.836923, val accuracy: 0.83\n",
            "Train accuracy: 0.99192, Train Loss: 0.081, val Loss: 0.827444, val accuracy: 0.83\n",
            "Train accuracy: 0.99232, Train Loss: 0.006, val Loss: 0.831061, val accuracy: 0.83\n",
            "Train accuracy: 0.99332, Train Loss: 0.004, val Loss: 0.841351, val accuracy: 0.83\n",
            "Train accuracy: 0.99404, Train Loss: 0.006, val Loss: 0.831057, val accuracy: 0.83\n",
            "Train accuracy: 0.99364, Train Loss: 0.053, val Loss: 0.855016, val accuracy: 0.83\n",
            "Train accuracy: 0.99372, Train Loss: 0.008, val Loss: 0.842036, val accuracy: 0.83\n",
            "Train accuracy: 0.99344, Train Loss: 0.001, val Loss: 0.841011, val accuracy: 0.83\n",
            "Train accuracy: 0.99416, Train Loss: 0.019, val Loss: 0.859234, val accuracy: 0.83\n",
            "Train accuracy: 0.99432, Train Loss: 0.043, val Loss: 0.848079, val accuracy: 0.83\n",
            "Train accuracy: 0.99432, Train Loss: 0.020, val Loss: 0.857580, val accuracy: 0.83\n",
            "Train accuracy: 0.99452, Train Loss: 0.002, val Loss: 0.870306, val accuracy: 0.83\n",
            "Train accuracy: 0.995, Train Loss: 0.001, val Loss: 0.865812, val accuracy: 0.83\n",
            "Train accuracy: 0.99508, Train Loss: 0.031, val Loss: 0.866380, val accuracy: 0.83\n",
            "Train accuracy: 0.99448, Train Loss: 0.033, val Loss: 0.866460, val accuracy: 0.83\n",
            "Train accuracy: 0.9952, Train Loss: 0.004, val Loss: 0.870713, val accuracy: 0.83\n",
            "Train accuracy: 0.9956, Train Loss: 0.022, val Loss: 0.882549, val accuracy: 0.83\n",
            "Train accuracy: 0.99548, Train Loss: 0.055, val Loss: 0.877129, val accuracy: 0.83\n",
            "Train accuracy: 0.99508, Train Loss: 0.001, val Loss: 0.878987, val accuracy: 0.83\n",
            "Train accuracy: 0.9956, Train Loss: 0.096, val Loss: 0.881700, val accuracy: 0.83\n",
            "Train accuracy: 0.99576, Train Loss: 0.003, val Loss: 0.884081, val accuracy: 0.83\n",
            "Train accuracy: 0.99528, Train Loss: 0.099, val Loss: 0.902275, val accuracy: 0.83\n",
            "Train accuracy: 0.99576, Train Loss: 0.019, val Loss: 0.879945, val accuracy: 0.83\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/train_accuracy</td><td></td></tr><tr><td>train/train_loss</td><td></td></tr><tr><td>val/val_accuracy</td><td></td></tr><tr><td>val/val_loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_accuracy</td><td>0.8</td></tr><tr><td>train/train_accuracy</td><td>1.0</td></tr><tr><td>train/train_loss</td><td>0.01871</td></tr><tr><td>val/val_accuracy</td><td>0.8346</td></tr><tr><td>val/val_loss</td><td>0.87995</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">Hyper_param3</strong> at: <a href='https://wandb.ai/avanti/resnet18_wandb_project/runs/qjpc3g8u' target=\"_blank\">https://wandb.ai/avanti/resnet18_wandb_project/runs/qjpc3g8u</a><br/>Synced 5 W&B file(s), 1 media file(s), 65 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230913_093106-qjpc3g8u/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyperparameter Set 4:"
      ],
      "metadata": {
        "id": "dMwyO_lJc7PV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create data loaders for training and testing\n",
        "batch_size = 128\n",
        "train_loader = torch.utils.data.DataLoader(trainset_2, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(testset_2, batch_size=batch_size, shuffle=False)\n",
        "n_steps_per_epoch = math.ceil(len(train_loader.dataset) /batch_size)\n",
        "\n",
        "\n",
        "wandb.init(\n",
        "    project=\"resnet18_wandb_project\",name=\"Hyper_param4\",\n",
        ")\n",
        "\n",
        "optimizer = torch.optim.RMSprop(model.parameters(), lr=0.01,momentum=0.9)\n",
        "main_fun(model, optimizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 925
        },
        "id": "WKVY-TphL2tY",
        "outputId": "392f1305-fbd2-472b-c52d-e993b71c7b44"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.10"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230913_093840-t8owbjz0</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/avanti/resnet18_wandb_project/runs/t8owbjz0' target=\"_blank\">Hyper_param4</a></strong> to <a href='https://wandb.ai/avanti/resnet18_wandb_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/avanti/resnet18_wandb_project' target=\"_blank\">https://wandb.ai/avanti/resnet18_wandb_project</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/avanti/resnet18_wandb_project/runs/t8owbjz0' target=\"_blank\">https://wandb.ai/avanti/resnet18_wandb_project/runs/t8owbjz0</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train accuracy: 0.34444, Train Loss: 3.639, val Loss: 1.940185, val accuracy: 0.29\n",
            "Train accuracy: 0.40256, Train Loss: 1.286, val Loss: 2.313123, val accuracy: 0.43\n",
            "Train accuracy: 0.47476, Train Loss: 1.088, val Loss: 1.088516, val accuracy: 0.57\n",
            "Train accuracy: 0.56384, Train Loss: 2.135, val Loss: 1.345823, val accuracy: 0.61\n",
            "Train accuracy: 0.64348, Train Loss: 1.053, val Loss: 0.991835, val accuracy: 0.63\n",
            "Train accuracy: 0.69772, Train Loss: 0.722, val Loss: 0.920502, val accuracy: 0.66\n",
            "Train accuracy: 0.73404, Train Loss: 0.521, val Loss: 0.764405, val accuracy: 0.71\n",
            "Train accuracy: 0.72104, Train Loss: 0.466, val Loss: 0.712273, val accuracy: 0.74\n",
            "Train accuracy: 0.7458, Train Loss: 0.544, val Loss: 0.776872, val accuracy: 0.73\n",
            "Train accuracy: 0.7308, Train Loss: 0.761, val Loss: 0.866811, val accuracy: 0.69\n",
            "Train accuracy: 0.72156, Train Loss: 0.982, val Loss: 1.160334, val accuracy: 0.68\n",
            "Train accuracy: 0.77792, Train Loss: 5.344, val Loss: 0.761498, val accuracy: 0.71\n",
            "Train accuracy: 0.77764, Train Loss: 0.520, val Loss: 0.651950, val accuracy: 0.77\n",
            "Train accuracy: 0.81456, Train Loss: 0.704, val Loss: 0.633925, val accuracy: 0.77\n",
            "Train accuracy: 0.80144, Train Loss: 0.633, val Loss: 0.844641, val accuracy: 0.73\n",
            "Train accuracy: 0.74372, Train Loss: 2.491, val Loss: 36.454819, val accuracy: 0.26\n",
            "Train accuracy: 0.6976, Train Loss: 0.875, val Loss: 2.652837, val accuracy: 0.71\n",
            "Train accuracy: 0.77096, Train Loss: 0.556, val Loss: 1.842372, val accuracy: 0.53\n",
            "Train accuracy: 0.80384, Train Loss: 0.403, val Loss: 3.620752, val accuracy: 0.53\n",
            "Train accuracy: 0.83144, Train Loss: 0.378, val Loss: 0.727804, val accuracy: 0.75\n",
            "Train accuracy: 0.84024, Train Loss: 0.719, val Loss: 0.879376, val accuracy: 0.77\n",
            "Train accuracy: 0.83968, Train Loss: 0.657, val Loss: 0.900016, val accuracy: 0.73\n",
            "Train accuracy: 0.84412, Train Loss: 0.588, val Loss: 0.696008, val accuracy: 0.78\n",
            "Train accuracy: 0.82956, Train Loss: 0.286, val Loss: 0.894863, val accuracy: 0.79\n",
            "Train accuracy: 0.87452, Train Loss: 0.557, val Loss: 0.677066, val accuracy: 0.80\n",
            "Train accuracy: 0.88364, Train Loss: 0.605, val Loss: 0.710389, val accuracy: 0.80\n",
            "Train accuracy: 0.8672, Train Loss: 0.296, val Loss: 0.814104, val accuracy: 0.79\n",
            "Train accuracy: 0.89732, Train Loss: 0.119, val Loss: 0.767137, val accuracy: 0.79\n",
            "Train accuracy: 0.89628, Train Loss: 0.316, val Loss: 0.859895, val accuracy: 0.78\n",
            "Train accuracy: 0.90216, Train Loss: 1.346, val Loss: 1.601032, val accuracy: 0.74\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/train_accuracy</td><td></td></tr><tr><td>train/train_loss</td><td></td></tr><tr><td>val/val_accuracy</td><td></td></tr><tr><td>val/val_loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_accuracy</td><td>0.8</td></tr><tr><td>train/train_accuracy</td><td>0.8</td></tr><tr><td>train/train_loss</td><td>1.34635</td></tr><tr><td>val/val_accuracy</td><td>0.7408</td></tr><tr><td>val/val_loss</td><td>1.60103</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">Hyper_param4</strong> at: <a href='https://wandb.ai/avanti/resnet18_wandb_project/runs/t8owbjz0' target=\"_blank\">https://wandb.ai/avanti/resnet18_wandb_project/runs/t8owbjz0</a><br/>Synced 5 W&B file(s), 1 media file(s), 129 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230913_093840-t8owbjz0/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Jy4plIffC5g4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J_GONlDgC5jy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}