{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Train a CNN based classification model and perform Optimized Hyperparameter Tuning using Optuna Library on the below-mentioned dataset. Perform 100 trials."
      ],
      "metadata": {
        "id": "RlykmwKWXfn3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reference:\n",
        "\n",
        "https://github.com/elena-ecn/optuna-optimization-for-PyTorch-CNN/blob/main/optuna_optimization.py\n"
      ],
      "metadata": {
        "id": "Q3Ea11BhaGnc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install optuna library"
      ],
      "metadata": {
        "id": "Oj9PWZF8Xqc3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWod2tAW90eY",
        "outputId": "014b27e5-6686-43a6-cdf2-6d76dbe4d8a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting optuna\n",
            "  Downloading optuna-3.1.1-py3-none-any.whl (365 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m365.7/365.7 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from optuna) (23.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.9/dist-packages (from optuna) (6.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.9/dist-packages (from optuna) (2.0.9)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from optuna) (1.22.4)\n",
            "Collecting cmaes>=0.9.1\n",
            "  Downloading cmaes-0.9.1-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from optuna) (4.65.0)\n",
            "Collecting colorlog\n",
            "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting alembic>=1.5.0\n",
            "  Downloading alembic-1.10.3-py3-none-any.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.3/212.3 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.9/dist-packages (from alembic>=1.5.0->optuna) (4.5.0)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.9/dist-packages (from sqlalchemy>=1.3.0->optuna) (2.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.9/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.2)\n",
            "Installing collected packages: Mako, colorlog, cmaes, alembic, optuna\n",
            "Successfully installed Mako-1.2.4 alembic-1.10.3 cmaes-0.9.1 colorlog-6.7.0 optuna-3.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import all required libraries"
      ],
      "metadata": {
        "id": "rpl36iZtXtXu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import optuna\n",
        "from optuna.trial import TrialState\n",
        "import torch.utils.data\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms"
      ],
      "metadata": {
        "id": "6wYeaaUxBR3C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set hyperparameters"
      ],
      "metadata": {
        "id": "bVFLVl_TXwRd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "Batch_size=128\n",
        "CLASSES=10\n",
        "EPOCHS=10\n",
        "N_training_samples=Batch_size*30\n",
        "N_validation_samples=Batch_size*10"
      ],
      "metadata": {
        "id": "rZWvxTM7Bkjg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the CNN model"
      ],
      "metadata": {
        "id": "tYcUpbEeZB_H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def define_model(trial):\n",
        "  #number of CNN layers are 3 to 5\n",
        "  n_layers=trial.suggest_int(\"n_layers\",3,5)\n",
        "  layers=[]\n",
        "  in_features=1\n",
        "  img_size=28\n",
        "  out_features=16\n",
        "  for i in range(n_layers):\n",
        "    #in_features are number of channels, out features are the output size of each layer\n",
        "    layers.append(nn.Conv2d(in_features, out_features, 3))\n",
        "    layers.append(nn.ReLU())\n",
        "    #By the convolution image size is decreasing by 2\n",
        "    img_size=img_size-2\n",
        "    #Update the input and output feature size for every layer\n",
        "    in_features=out_features\n",
        "    out_features=out_features*2\n",
        "  #Flatten the layer\n",
        "  layers.append(nn.Flatten())\n",
        "  #Get number of classes output\n",
        "  layers.append(nn.Linear(in_features*img_size*img_size, CLASSES))\n",
        "  layers.append(nn.LogSoftmax(dim=1))\n",
        "\n",
        "  return nn.Sequential(*layers)"
      ],
      "metadata": {
        "id": "SBJr7oUKCgfq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load dataset"
      ],
      "metadata": {
        "id": "ZV3AvUhrZuKi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
        "testset = datasets.MNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())\n",
        "train_loader = torch.utils.data.DataLoader(trainset, batch_size=Batch_size, shuffle=True, num_workers=2)\n",
        "valid_loader = torch.utils.data.DataLoader(testset, batch_size=Batch_size, shuffle=True, num_workers=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAPdGwYcEghi",
        "outputId": "637644ab-c7d3-46ce-ff9f-5b2a6cb479d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 123006154.62it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 111542996.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 43753464.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 4708484.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "train function"
      ],
      "metadata": {
        "id": "Ub3pih8AfdVG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_function(model,train_loader,optimizer):\n",
        "  model.train()\n",
        "  for batch_idx, (data, target) in enumerate(train_loader):\n",
        "      if batch_idx*Batch_size>=N_training_samples:\n",
        "        break\n",
        "\n",
        "      data, target =data.to(device),target.to(device)\n",
        "      optimizer.zero_grad()\n",
        "      output = model(data)\n",
        "      #calculate loss function\n",
        "      loss = F.nll_loss(output, target)\n",
        "      loss.backward()\n",
        "      optimizer.step()"
      ],
      "metadata": {
        "id": "dotjmZFseFeg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test function"
      ],
      "metadata": {
        "id": "zkLIQvmxfh5b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_function(model, valid_loader,criterion):\n",
        "  model.eval()\n",
        "  #variable to keep track of correctly classified samples\n",
        "  correct=0\n",
        "  with torch.no_grad():\n",
        "    for batch_idx, (data, target) in enumerate(valid_loader):\n",
        "        if batch_idx*Batch_size>=N_validation_samples:\n",
        "          break\n",
        "\n",
        "        data, target =data.to(device),target.to(device)\n",
        "        output = model(data)\n",
        "        pred=output.argmax(dim=1,keepdim=True)\n",
        "        correct+=pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "  accuracy=correct/min(len(valid_loader.dataset),N_validation_samples)\n",
        "  return accuracy"
      ],
      "metadata": {
        "id": "F0T5mWTkeTKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Objective function to run the model"
      ],
      "metadata": {
        "id": "tg4xJNi9ZwBy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial):\n",
        "    model=define_model(trial).to(device)\n",
        "    #Number of epochs are mentioned as 10 to 50\n",
        "    num_epochs = trial.suggest_int('num_epochs', 10, 50)\n",
        "    #Choose learning rate from 1e-4, 1e-1 range\n",
        "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-4, 1e-1, log=True)\n",
        "\n",
        "    # Define the optimizer and loss function\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Training of the model\n",
        "    for epoch in range(num_epochs):\n",
        "        train_function(model,train_loader,optimizer,criterion)\n",
        "        accuracy=test_function(model, valid_loader)\n",
        "\n",
        "        # Pruning, to stop early if it is not giving good results\n",
        "        trial.report(accuracy, epoch)\n",
        "        # Handle pruning based on the intermediate value.\n",
        "        if trial.should_prune():\n",
        "            raise optuna.exceptions.TrialPruned()\n",
        "\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "QaLmeCQUEYIa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Driver code"
      ],
      "metadata": {
        "id": "lNqenV8sWk7u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an Optuna study to maximize test accuracy\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=100)\n",
        "# Find number of pruned and completed trials\n",
        "pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
        "complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
        "\n",
        "# Display the study statistics\n",
        "print(\"\\nStudy statistics: \")\n",
        "print(\"  Number of finished trials: \", len(study.trials))\n",
        "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
        "print(\"  Number of complete trials: \", len(complete_trials))\n",
        "\n",
        "trial = study.best_trial\n",
        "print(\"Best trial:\")\n",
        "print(\"  Value: \", trial.value)\n",
        "print(\"  Params: \")\n",
        "for key, value in trial.params.items():\n",
        "    print(\"    {}: {}\".format(key, value))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYUpbqFaJGdE",
        "outputId": "911386f6-3f55-48eb-ab08-d7ca085744b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2023-04-22 19:05:23,452]\u001b[0m A new study created in memory with name: no-name-4ac71109-cbdd-49e8-ac4f-f436fd67315b\u001b[0m\n",
            "\u001b[32m[I 2023-04-22 19:05:53,562]\u001b[0m Trial 0 finished with value: 0.9875 and parameters: {'n_layers': 3, 'num_epochs': 25, 'learning_rate': 0.0016415001469332474}. Best is trial 0 with value: 0.9875.\u001b[0m\n",
            "\u001b[32m[I 2023-04-22 19:06:16,937]\u001b[0m Trial 1 finished with value: 0.94921875 and parameters: {'n_layers': 3, 'num_epochs': 20, 'learning_rate': 0.00010191922414885857}. Best is trial 0 with value: 0.9875.\u001b[0m\n",
            "\u001b[32m[I 2023-04-22 19:07:03,465]\u001b[0m Trial 2 finished with value: 0.97734375 and parameters: {'n_layers': 5, 'num_epochs': 36, 'learning_rate': 0.004198283595653838}. Best is trial 0 with value: 0.9875.\u001b[0m\n",
            "\u001b[32m[I 2023-04-22 19:08:00,545]\u001b[0m Trial 3 finished with value: 0.93984375 and parameters: {'n_layers': 4, 'num_epochs': 47, 'learning_rate': 0.016232497204092512}. Best is trial 0 with value: 0.9875.\u001b[0m\n",
            "\u001b[32m[I 2023-04-22 19:09:02,466]\u001b[0m Trial 4 finished with value: 0.11484375 and parameters: {'n_layers': 5, 'num_epochs': 47, 'learning_rate': 0.07582442285066408}. Best is trial 0 with value: 0.9875.\u001b[0m\n",
            "\u001b[32m[I 2023-04-22 19:09:23,333]\u001b[0m Trial 5 finished with value: 0.98046875 and parameters: {'n_layers': 5, 'num_epochs': 16, 'learning_rate': 0.004803856275598473}. Best is trial 0 with value: 0.9875.\u001b[0m\n",
            "\u001b[32m[I 2023-04-22 19:10:17,869]\u001b[0m Trial 6 finished with value: 0.98671875 and parameters: {'n_layers': 3, 'num_epochs': 46, 'learning_rate': 0.008432132461104056}. Best is trial 0 with value: 0.9875.\u001b[0m\n",
            "\u001b[32m[I 2023-04-22 19:10:19,217]\u001b[0m Trial 7 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-22 19:10:21,439]\u001b[0m Trial 8 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-22 19:10:53,096]\u001b[0m Trial 9 finished with value: 0.9796875 and parameters: {'n_layers': 3, 'num_epochs': 27, 'learning_rate': 0.003531207737574056}. Best is trial 0 with value: 0.9875.\u001b[0m\n",
            "\u001b[32m[I 2023-04-22 19:10:54,928]\u001b[0m Trial 10 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-22 19:11:40,442]\u001b[0m Trial 11 finished with value: 0.98359375 and parameters: {'n_layers': 3, 'num_epochs': 39, 'learning_rate': 0.000986173713170696}. Best is trial 0 with value: 0.9875.\u001b[0m\n",
            "\u001b[32m[I 2023-04-22 19:11:41,608]\u001b[0m Trial 12 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-22 19:11:42,715]\u001b[0m Trial 13 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-22 19:12:09,272]\u001b[0m Trial 14 finished with value: 0.9828125 and parameters: {'n_layers': 3, 'num_epochs': 22, 'learning_rate': 0.0014937387983345238}. Best is trial 0 with value: 0.9875.\u001b[0m\n",
            "\u001b[32m[I 2023-04-22 19:12:10,958]\u001b[0m Trial 15 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-22 19:12:12,064]\u001b[0m Trial 16 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-22 19:13:04,512]\u001b[0m Trial 17 finished with value: 0.9828125 and parameters: {'n_layers': 4, 'num_epochs': 43, 'learning_rate': 0.002275620443775674}. Best is trial 0 with value: 0.9875.\u001b[0m\n",
            "\u001b[32m[I 2023-04-22 19:13:05,644]\u001b[0m Trial 18 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-22 19:13:06,747]\u001b[0m Trial 19 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-22 19:13:07,902]\u001b[0m Trial 20 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-22 19:13:54,108]\u001b[0m Trial 21 finished with value: 0.98203125 and parameters: {'n_layers': 3, 'num_epochs': 38, 'learning_rate': 0.0017644831837101264}. Best is trial 0 with value: 0.9875.\u001b[0m\n",
            "\u001b[32m[I 2023-04-22 19:14:00,792]\u001b[0m Trial 22 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-22 19:14:45,697]\u001b[0m Trial 23 finished with value: 0.98671875 and parameters: {'n_layers': 3, 'num_epochs': 37, 'learning_rate': 0.0034384102420950136}. Best is trial 0 with value: 0.9875.\u001b[0m\n",
            "\u001b[32m[I 2023-04-22 19:15:27,511]\u001b[0m Trial 24 finished with value: 0.9890625 and parameters: {'n_layers': 3, 'num_epochs': 35, 'learning_rate': 0.002787374207259564}. Best is trial 24 with value: 0.9890625.\u001b[0m\n",
            "\u001b[32m[I 2023-04-22 19:16:08,384]\u001b[0m Trial 25 finished with value: 0.990625 and parameters: {'n_layers': 3, 'num_epochs': 34, 'learning_rate': 0.006393885407197871}. Best is trial 25 with value: 0.990625.\u001b[0m\n",
            "\u001b[32m[I 2023-04-22 19:16:10,388]\u001b[0m Trial 26 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-22 19:16:14,908]\u001b[0m Trial 27 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-22 19:16:29,648]\u001b[0m Trial 28 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-22 19:16:31,319]\u001b[0m Trial 29 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-22 19:16:32,986]\u001b[0m Trial 30 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-22 19:16:43,659]\u001b[0m Trial 31 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-22 19:17:42,335]\u001b[0m Trial 32 finished with value: 0.984375 and parameters: {'n_layers': 3, 'num_epochs': 45, 'learning_rate': 0.004239402260198875}. Best is trial 25 with value: 0.990625.\u001b[0m\n",
            "\u001b[32m[I 2023-04-22 19:17:43,481]\u001b[0m Trial 33 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-22 19:17:49,422]\u001b[0m Trial 34 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-22 19:17:51,251]\u001b[0m Trial 35 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-22 19:17:52,648]\u001b[0m Trial 36 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-22 19:17:53,776]\u001b[0m Trial 37 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-22 19:18:05,907]\u001b[0m Trial 38 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-22 19:18:07,107]\u001b[0m Trial 39 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-22 19:18:11,607]\u001b[0m Trial 40 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-22 19:18:15,825]\u001b[0m Trial 41 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-22 19:18:20,494]\u001b[0m Trial 42 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-22 19:18:22,830]\u001b[0m Trial 43 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-22 19:18:28,199]\u001b[0m Trial 44 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-22 19:18:29,745]\u001b[0m Trial 45 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-22 19:19:14,325]\u001b[0m Trial 46 finished with value: 0.98515625 and parameters: {'n_layers': 3, 'num_epochs': 37, 'learning_rate': 0.0037641484025000616}. Best is trial 25 with value: 0.990625.\u001b[0m\n",
            "\u001b[32m[I 2023-04-22 19:19:15,517]\u001b[0m Trial 47 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-22 19:19:16,735]\u001b[0m Trial 48 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-22 19:19:18,625]\u001b[0m Trial 49 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-22 19:19:20,054]\u001b[0m Trial 50 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-22 19:20:04,902]\u001b[0m Trial 51 finished with value: 0.990625 and parameters: {'n_layers': 3, 'num_epochs': 37, 'learning_rate': 0.0039994306785027635}. Best is trial 25 with value: 0.990625.\u001b[0m\n",
            "\u001b[32m[I 2023-04-22 19:20:07,460]\u001b[0m Trial 52 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-22 19:20:09,414]\u001b[0m Trial 53 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-22 19:20:10,556]\u001b[0m Trial 54 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-22 19:20:11,687]\u001b[0m Trial 55 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-22 19:20:12,864]\u001b[0m Trial 56 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-22 19:21:02,348]\u001b[0m Trial 57 finished with value: 0.98515625 and parameters: {'n_layers': 3, 'num_epochs': 40, 'learning_rate': 0.0027984012626340897}. Best is trial 25 with value: 0.990625.\u001b[0m\n",
            "\u001b[32m[I 2023-04-22 19:21:36,914]\u001b[0m Trial 58 finished with value: 0.9765625 and parameters: {'n_layers': 3, 'num_epochs': 28, 'learning_rate': 0.005389379679978784}. Best is trial 25 with value: 0.990625.\u001b[0m\n",
            "\u001b[32m[I 2023-04-22 19:21:38,278]\u001b[0m Trial 59 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-22 19:21:39,451]\u001b[0m Trial 60 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-22 19:22:24,492]\u001b[0m Trial 61 finished with value: 0.98515625 and parameters: {'n_layers': 3, 'num_epochs': 37, 'learning_rate': 0.0038222885000803956}. Best is trial 25 with value: 0.990625.\u001b[0m\n",
            "\u001b[32m[I 2023-04-22 19:23:12,081]\u001b[0m Trial 62 finished with value: 0.9859375 and parameters: {'n_layers': 3, 'num_epochs': 38, 'learning_rate': 0.0022822135225375527}. Best is trial 25 with value: 0.990625.\u001b[0m\n",
            "\u001b[32m[I 2023-04-22 19:23:26,011]\u001b[0m Trial 63 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-22 19:23:27,190]\u001b[0m Trial 64 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-22 19:23:31,792]\u001b[0m Trial 65 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-22 19:23:35,206]\u001b[0m Trial 66 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-22 19:23:36,408]\u001b[0m Trial 67 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-22 19:23:37,591]\u001b[0m Trial 68 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-22 19:23:38,863]\u001b[0m Trial 69 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-22 19:23:40,056]\u001b[0m Trial 70 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-22 19:24:27,166]\u001b[0m Trial 71 finished with value: 0.98203125 and parameters: {'n_layers': 3, 'num_epochs': 37, 'learning_rate': 0.0038757245897123025}. Best is trial 25 with value: 0.990625.\u001b[0m\n",
            "\u001b[32m[I 2023-04-22 19:24:28,354]\u001b[0m Trial 72 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-22 19:24:29,529]\u001b[0m Trial 73 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-22 19:24:30,743]\u001b[0m Trial 74 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-22 19:24:32,304]\u001b[0m Trial 75 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-22 19:24:34,147]\u001b[0m Trial 76 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-22 19:24:35,340]\u001b[0m Trial 77 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-22 19:24:37,703]\u001b[0m Trial 78 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-22 19:24:38,889]\u001b[0m Trial 79 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-22 19:24:40,272]\u001b[0m Trial 80 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-22 19:24:41,444]\u001b[0m Trial 81 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-22 19:24:43,737]\u001b[0m Trial 82 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-22 19:24:47,136]\u001b[0m Trial 83 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-22 19:24:50,668]\u001b[0m Trial 84 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-22 19:24:51,872]\u001b[0m Trial 85 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-22 19:24:53,088]\u001b[0m Trial 86 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-22 19:24:54,308]\u001b[0m Trial 87 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-22 19:24:55,474]\u001b[0m Trial 88 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-22 19:24:56,665]\u001b[0m Trial 89 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-22 19:25:01,245]\u001b[0m Trial 90 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-22 19:25:02,486]\u001b[0m Trial 91 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-22 19:25:50,743]\u001b[0m Trial 92 finished with value: 0.9921875 and parameters: {'n_layers': 3, 'num_epochs': 38, 'learning_rate': 0.002936918342296688}. Best is trial 92 with value: 0.9921875.\u001b[0m\n",
            "\u001b[32m[I 2023-04-22 19:25:51,900]\u001b[0m Trial 93 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-22 19:25:53,086]\u001b[0m Trial 94 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-22 19:25:57,710]\u001b[0m Trial 95 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-22 19:25:58,868]\u001b[0m Trial 96 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-22 19:26:00,085]\u001b[0m Trial 97 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-22 19:26:03,412]\u001b[0m Trial 98 pruned. \u001b[0m\n",
            "\u001b[32m[I 2023-04-22 19:26:04,593]\u001b[0m Trial 99 pruned. \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Study statistics: \n",
            "  Number of finished trials:  100\n",
            "  Number of pruned trials:  76\n",
            "  Number of complete trials:  24\n",
            "Best trial:\n",
            "  Value:  0.9921875\n",
            "  Params: \n",
            "    n_layers: 3\n",
            "    num_epochs: 38\n",
            "    learning_rate: 0.002936918342296688\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gm8BkTnC9oIC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}